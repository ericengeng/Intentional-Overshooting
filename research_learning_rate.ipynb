{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "DK9Pf1qQMIaK",
        "outputId": "5fa30f29-3c5d-4677-b137-da32fc5d3f91"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def cyclic_lr(iteration, step_size, base_lr, max_lr):\n",
        "    \"\"\"Calculate the learning rate for a given iteration using the triangular policy.\n",
        "\n",
        "    Args:\n",
        "        iteration (int): The current iteration.\n",
        "        step_size (int): The number of iterations in half a cycle.\n",
        "        base_lr (float): The minimum learning rate (lower boundary).\n",
        "        max_lr (float): The maximum learning rate (upper boundary).\n",
        "\n",
        "    Returns:\n",
        "        float: The calculated learning rate for the current iteration.\n",
        "    \"\"\"\n",
        "    cycle = np.floor(1 + iteration / (2 * step_size))\n",
        "    x = np.abs(iteration / step_size - 2 * cycle + 1)\n",
        "    lr = base_lr + (max_lr - base_lr) * np.maximum(0, (1 - x))\n",
        "    return lr\n",
        "\n",
        "# Example usage\n",
        "iterations = 10000\n",
        "step_size = 1000  # Half of the cycle length\n",
        "base_lr = 0.001\n",
        "max_lr = 0.006\n",
        "\n",
        "lrs = [cyclic_lr(i, step_size, base_lr, max_lr) for i in range(iterations)]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(lrs)\n",
        "plt.title('Cyclical Learning Rate (Triangular Policy)')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def create_cnn_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = create_cnn_model()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdF9IsxwSBJx",
        "outputId": "b2633dad-57c1-4f77-ae98-cdf53122ad1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_192 (Conv2D)         (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " conv2d_193 (Conv2D)         (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_96 (MaxPooli  (None, 14, 14, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_144 (Dropout)       (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_194 (Conv2D)         (None, 12, 12, 64)        36928     \n",
            "                                                                 \n",
            " conv2d_195 (Conv2D)         (None, 10, 10, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_97 (MaxPooli  (None, 5, 5, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_145 (Dropout)       (None, 5, 5, 64)          0         \n",
            "                                                                 \n",
            " flatten_48 (Flatten)        (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_96 (Dense)            (None, 512)               819712    \n",
            "                                                                 \n",
            " dropout_146 (Dropout)       (None, 512)               0         \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 918090 (3.50 MB)\n",
            "Trainable params: 918090 (3.50 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "\n",
        "class CyclicLR(Callback):\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "    def clr(self):\n",
        "        cycle = np.floor(1 + self.clr_iterations / (2 * self.step_size))\n",
        "        x = np.abs(self.clr_iterations / self.step_size - 2 * cycle + 1)\n",
        "        if self.mode == 'triangular':\n",
        "            return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0, (1 - x))\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        logs = logs or {}\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())\n",
        "\n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "        K.set_value(self.model.optimizer.lr, self.clr())\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n"
      ],
      "metadata": {
        "id": "oyCBswldSZMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load and preprocess the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
      ],
      "metadata": {
        "id": "nlfKucpopnLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the model (as previously defined)\n",
        "model = create_cnn_model()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Initialize the CLR callback\n",
        "clr = CyclicLR(base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=60, # Adjust epochs based on your requirements\n",
        "                    batch_size=64,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=[clr])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "Cr5cK-c3Scac",
        "outputId": "371ac5e3-0795-4c1f-b73a-a15bad21ed94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "782/782 [==============================] - 9s 9ms/step - loss: 1.5718 - accuracy: 0.4243 - val_loss: 1.2552 - val_accuracy: 0.5431\n",
            "Epoch 2/60\n",
            "393/782 [==============>...............] - ETA: 2s - loss: 1.2997 - accuracy: 0.5356"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-16a70160a986>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m history = model.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Adjust epochs based on your requirements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;31m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\u001b[0m in \u001b[0;36munpack_inputs\u001b[0;34m(self, bound_parameters)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m       flat.extend(\n\u001b[0;32m--> 391\u001b[0;31m           \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_constraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m       )\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36mto_tensors\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     nest.map_structure(\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mlambda\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_component_specs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m   \"\"\"\n\u001b[0;32m--> 631\u001b[0;31m   return nest_util.map_structure(\n\u001b[0m\u001b[1;32m    632\u001b[0m       \u001b[0mnest_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1064\u001b[0m   \"\"\"\n\u001b[1;32m   1065\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_core_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_data_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m   \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m   return _tf_core_pack_sequence_as(\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m_tf_core_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    918\u001b[0m           \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       )\n\u001b[0;32m--> 920\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msequence_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36msequence_like\u001b[0;34m(instance, args)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;31m# in the proxy type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCustomNestProtocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tf_flatten__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tf_unflatten__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/typing.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m   1504\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_protocol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1506\u001b[0;31m             if all(hasattr(instance, attr) and\n\u001b[0m\u001b[1;32m   1507\u001b[0m                     \u001b[0;31m# All *methods* can be blocked by setting them to None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m                     (not callable(getattr(cls, attr, None)) or\n",
            "\u001b[0;32m/usr/lib/python3.10/typing.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1504\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_protocol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1506\u001b[0;31m             if all(hasattr(instance, attr) and\n\u001b[0m\u001b[1;32m   1507\u001b[0m                     \u001b[0;31m# All *methods* can be blocked by setting them to None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m                     (not callable(getattr(cls, attr, None)) or\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "\n",
        "# Define the sequence of step sizes\n",
        "step_sizes = [1, 0.1, 0.01, 0.001, 0.0001]\n",
        "\n",
        "previous_best_model_path = None\n",
        "\n",
        "for step_size in step_sizes:\n",
        "    # Initialize the model\n",
        "    model = create_cnn_model()\n",
        "\n",
        "    # If there's a model from the previous step, load its weights\n",
        "    if previous_best_model_path and os.path.exists(previous_best_model_path):\n",
        "        model.load_weights(previous_best_model_path)\n",
        "        print(f\"Loaded weights from {previous_best_model_path}\")\n",
        "\n",
        "    # Compile the model with the current step size\n",
        "    model.compile(optimizer=Adam(lr=step_size),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Define the checkpoint callback to save the best model\n",
        "    checkpoint_filepath = f'best_model_step_size_{step_size}.h5'\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train,\n",
        "              epochs=5,\n",
        "              batch_size=64,\n",
        "              validation_data=(x_test, y_test),\n",
        "              callbacks=[model_checkpoint_callback])\n",
        "\n",
        "    # Update the path of the best model for the next iteration\n",
        "    previous_best_model_path = checkpoint_filepath\n",
        "\n",
        "    print(f\"Training completed with step size {step_size}. Best model saved to {checkpoint_filepath}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "id": "Z38aYOFoUWYd",
        "outputId": "1b3da85e-6332-4b9d-80c1-3b3d3e9c6f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 9s 9ms/step - loss: 1.5654 - accuracy: 0.4237 - val_loss: 1.1996 - val_accuracy: 0.5694\n",
            "Epoch 2/5\n",
            " 15/782 [..............................] - ETA: 6s - loss: 1.2146 - accuracy: 0.5708"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1519 - accuracy: 0.5895 - val_loss: 0.9713 - val_accuracy: 0.6605\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.9878 - accuracy: 0.6478 - val_loss: 0.9025 - val_accuracy: 0.6837\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.8826 - accuracy: 0.6898 - val_loss: 0.7981 - val_accuracy: 0.7192\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.8155 - accuracy: 0.7139 - val_loss: 0.7976 - val_accuracy: 0.7214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 1. Best model saved to best_model_step_size_1.h5.\n",
            "Loaded weights from best_model_step_size_1.h5\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 9s 9ms/step - loss: 0.7578 - accuracy: 0.7329 - val_loss: 0.7208 - val_accuracy: 0.7487\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7214 - accuracy: 0.7437 - val_loss: 0.6980 - val_accuracy: 0.7545\n",
            "Epoch 3/5\n",
            "517/782 [==================>...........] - ETA: 2s - loss: 0.6845 - accuracy: 0.7576"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2cb7c3fa377a>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     model.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m     38\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\u001b[0m in \u001b[0;36mpack_output\u001b[0;34m(self, flat_values)\u001b[0m\n\u001b[1;32m    444\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can not pack outputs for undefined output type.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\u001b[0m in \u001b[0;36mfrom_tensors\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m    762\u001b[0m     sorted_traversal = {\n\u001b[1;32m    763\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     }\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "\n",
        "# Define the sequence of step sizes\n",
        "step_sizes = [1, 0.1, 0.01, 0.001, 0.0001]\n",
        "epochs = [20,10,10,10,10]\n",
        "\n",
        "previous_best_model_path = None\n",
        "\n",
        "for i in range(len(step_sizes)):\n",
        "    # Initialize the model\n",
        "    step_size = step_sizes[i]\n",
        "    epoch = epochs[i]\n",
        "    model = create_cnn_model()\n",
        "\n",
        "    # If there's a model from the previous step, load its weights\n",
        "    if previous_best_model_path and os.path.exists(previous_best_model_path):\n",
        "        model.load_weights(previous_best_model_path)\n",
        "        print(f\"Loaded weights from {previous_best_model_path}\")\n",
        "\n",
        "    # Compile the model with the current step size\n",
        "    model.compile(optimizer=Adam(lr=step_size),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Define the checkpoint callback to save the best model\n",
        "    checkpoint_filepath = f'best_model_step_size_{step_size}.h5'\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train,\n",
        "              epochs=epoch,\n",
        "              batch_size=64,\n",
        "              validation_data=(x_test, y_test),\n",
        "              callbacks=[model_checkpoint_callback])\n",
        "\n",
        "    # Update the path of the best model for the next iteration\n",
        "    previous_best_model_path = checkpoint_filepath\n",
        "\n",
        "    print(f\"Training completed with step size {step_size}. Best model saved to {checkpoint_filepath}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzktjCH3YuOE",
        "outputId": "2d6cad1b-ac4d-4a44-b7cd-8e70782614d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 9s 10ms/step - loss: 1.5924 - accuracy: 0.4156 - val_loss: 1.2823 - val_accuracy: 0.5326\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1620 - accuracy: 0.5856 - val_loss: 0.9985 - val_accuracy: 0.6464\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.9733 - accuracy: 0.6576 - val_loss: 0.8676 - val_accuracy: 0.6966\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.8678 - accuracy: 0.6944 - val_loss: 0.7890 - val_accuracy: 0.7229\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7968 - accuracy: 0.7202 - val_loss: 0.7179 - val_accuracy: 0.7502\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7432 - accuracy: 0.7390 - val_loss: 0.7352 - val_accuracy: 0.7470\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7057 - accuracy: 0.7522 - val_loss: 0.7189 - val_accuracy: 0.7480\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.6708 - accuracy: 0.7625 - val_loss: 0.6702 - val_accuracy: 0.7681\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.6394 - accuracy: 0.7746 - val_loss: 0.6813 - val_accuracy: 0.7672\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.6131 - accuracy: 0.7819 - val_loss: 0.6808 - val_accuracy: 0.7645\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.5892 - accuracy: 0.7917 - val_loss: 0.6433 - val_accuracy: 0.7789\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.5632 - accuracy: 0.8001 - val_loss: 0.6454 - val_accuracy: 0.7790\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.5498 - accuracy: 0.8059 - val_loss: 0.6867 - val_accuracy: 0.7719\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.5234 - accuracy: 0.8132 - val_loss: 0.6594 - val_accuracy: 0.7751\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.5120 - accuracy: 0.8168 - val_loss: 0.6279 - val_accuracy: 0.7849\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.4984 - accuracy: 0.8242 - val_loss: 0.6544 - val_accuracy: 0.7816\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4846 - accuracy: 0.8265 - val_loss: 0.6283 - val_accuracy: 0.7960\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4757 - accuracy: 0.8291 - val_loss: 0.6528 - val_accuracy: 0.7886\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4616 - accuracy: 0.8345 - val_loss: 0.6465 - val_accuracy: 0.7886\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4513 - accuracy: 0.8391 - val_loss: 0.6386 - val_accuracy: 0.7912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 1. Best model saved to best_model_step_size_1.h5.\n",
            "Loaded weights from best_model_step_size_1.h5\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 9s 10ms/step - loss: 0.4766 - accuracy: 0.8314 - val_loss: 0.6420 - val_accuracy: 0.7895\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4610 - accuracy: 0.8362 - val_loss: 0.6293 - val_accuracy: 0.7961\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4606 - accuracy: 0.8352 - val_loss: 0.6319 - val_accuracy: 0.7937\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4453 - accuracy: 0.8424 - val_loss: 0.6582 - val_accuracy: 0.7886\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4334 - accuracy: 0.8467 - val_loss: 0.6369 - val_accuracy: 0.7874\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4299 - accuracy: 0.8489 - val_loss: 0.6398 - val_accuracy: 0.7967\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4240 - accuracy: 0.8484 - val_loss: 0.6194 - val_accuracy: 0.7985\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4165 - accuracy: 0.8538 - val_loss: 0.6291 - val_accuracy: 0.7961\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4119 - accuracy: 0.8548 - val_loss: 0.6530 - val_accuracy: 0.7909\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4099 - accuracy: 0.8533 - val_loss: 0.6280 - val_accuracy: 0.8010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 0.1. Best model saved to best_model_step_size_0.1.h5.\n",
            "Loaded weights from best_model_step_size_0.1.h5\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 9s 10ms/step - loss: 0.3957 - accuracy: 0.8597 - val_loss: 0.6440 - val_accuracy: 0.8006\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.3899 - accuracy: 0.8612 - val_loss: 0.6394 - val_accuracy: 0.7992\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3819 - accuracy: 0.8620 - val_loss: 0.6815 - val_accuracy: 0.7882\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3851 - accuracy: 0.8631 - val_loss: 0.6313 - val_accuracy: 0.8013\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3787 - accuracy: 0.8659 - val_loss: 0.6566 - val_accuracy: 0.7972\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3715 - accuracy: 0.8678 - val_loss: 0.6591 - val_accuracy: 0.7924\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3750 - accuracy: 0.8664 - val_loss: 0.6377 - val_accuracy: 0.7981\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3626 - accuracy: 0.8703 - val_loss: 0.6508 - val_accuracy: 0.7936\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.3587 - accuracy: 0.8750 - val_loss: 0.6782 - val_accuracy: 0.7956\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3631 - accuracy: 0.8705 - val_loss: 0.6491 - val_accuracy: 0.7958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 0.01. Best model saved to best_model_step_size_0.01.h5.\n",
            "Loaded weights from best_model_step_size_0.01.h5\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 9s 9ms/step - loss: 0.3877 - accuracy: 0.8625 - val_loss: 0.6341 - val_accuracy: 0.8011\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3770 - accuracy: 0.8655 - val_loss: 0.6470 - val_accuracy: 0.7961\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3685 - accuracy: 0.8698 - val_loss: 0.6230 - val_accuracy: 0.8024\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3669 - accuracy: 0.8700 - val_loss: 0.6502 - val_accuracy: 0.7933\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3599 - accuracy: 0.8726 - val_loss: 0.6789 - val_accuracy: 0.7974\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3550 - accuracy: 0.8750 - val_loss: 0.6416 - val_accuracy: 0.8032\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.3588 - accuracy: 0.8759 - val_loss: 0.6620 - val_accuracy: 0.7996\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3562 - accuracy: 0.8751 - val_loss: 0.6596 - val_accuracy: 0.7981\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3495 - accuracy: 0.8762 - val_loss: 0.6917 - val_accuracy: 0.7924\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3466 - accuracy: 0.8772 - val_loss: 0.6726 - val_accuracy: 0.7929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 0.001. Best model saved to best_model_step_size_0.001.h5.\n",
            "Loaded weights from best_model_step_size_0.001.h5\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 10s 9ms/step - loss: 0.3561 - accuracy: 0.8735 - val_loss: 0.6543 - val_accuracy: 0.7943\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3501 - accuracy: 0.8768 - val_loss: 0.6934 - val_accuracy: 0.7924\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3506 - accuracy: 0.8757 - val_loss: 0.6772 - val_accuracy: 0.8004\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3378 - accuracy: 0.8801 - val_loss: 0.6733 - val_accuracy: 0.7990\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3428 - accuracy: 0.8797 - val_loss: 0.6523 - val_accuracy: 0.8011\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.3383 - accuracy: 0.8817 - val_loss: 0.6537 - val_accuracy: 0.8009\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3376 - accuracy: 0.8810 - val_loss: 0.6583 - val_accuracy: 0.8024\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.3332 - accuracy: 0.8815 - val_loss: 0.6682 - val_accuracy: 0.7984\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3289 - accuracy: 0.8850 - val_loss: 0.6528 - val_accuracy: 0.8021\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3272 - accuracy: 0.8851 - val_loss: 0.6752 - val_accuracy: 0.7995\n",
            "Training completed with step size 0.0001. Best model saved to best_model_step_size_0.0001.h5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "\n",
        "# Define the sequence of step sizes\n",
        "step_sizes = [5,1, 0.1, 0.01, 0.001, 0.0001]\n",
        "epochs = [5,20,10,10,10,10]\n",
        "\n",
        "previous_best_model_path = None\n",
        "\n",
        "for i in range(len(step_sizes)):\n",
        "    # Initialize the model\n",
        "    step_size = step_sizes[i]\n",
        "    epoch = epochs[i]\n",
        "    model = create_cnn_model()\n",
        "\n",
        "    # If there's a model from the previous step, load its weights\n",
        "    if previous_best_model_path and os.path.exists(previous_best_model_path):\n",
        "        model.load_weights(previous_best_model_path)\n",
        "        print(f\"Loaded weights from {previous_best_model_path}\")\n",
        "\n",
        "    # Compile the model with the current step size\n",
        "    model.compile(optimizer=SGD(lr=step_size),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Define the checkpoint callback to save the best model\n",
        "    checkpoint_filepath = f'best_model_step_size_{step_size}.h5'\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train,\n",
        "              epochs=epoch,\n",
        "              batch_size=64,\n",
        "              validation_data=(x_test, y_test),\n",
        "              callbacks=[model_checkpoint_callback])\n",
        "\n",
        "    # Update the path of the best model for the next iteration\n",
        "    previous_best_model_path = checkpoint_filepath\n",
        "\n",
        "    print(f\"Training completed with step size {step_size}. Best model saved to {checkpoint_filepath}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUTKttQKpr35",
        "outputId": "7f5f7649-4d16-4ba6-bd91-29cd1c5f20ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 2.2049 - accuracy: 0.1614 - val_loss: 2.3730 - val_accuracy: 0.1691\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.9879 - accuracy: 0.2655 - val_loss: 1.8246 - val_accuracy: 0.3521\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.8232 - accuracy: 0.3331 - val_loss: 1.8254 - val_accuracy: 0.3441\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.7188 - accuracy: 0.3702 - val_loss: 1.5879 - val_accuracy: 0.4180\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.6291 - accuracy: 0.4026 - val_loss: 1.5885 - val_accuracy: 0.4080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 5. Best model saved to best_model_step_size_5.h5.\n",
            "Loaded weights from best_model_step_size_5.h5\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 1.6311 - accuracy: 0.4018 - val_loss: 1.7848 - val_accuracy: 0.3759\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.5490 - accuracy: 0.4335 - val_loss: 1.4769 - val_accuracy: 0.4703\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4785 - accuracy: 0.4624 - val_loss: 1.3796 - val_accuracy: 0.5049\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4239 - accuracy: 0.4840 - val_loss: 1.4300 - val_accuracy: 0.4823\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3751 - accuracy: 0.5069 - val_loss: 1.2676 - val_accuracy: 0.5433\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3334 - accuracy: 0.5183 - val_loss: 1.2703 - val_accuracy: 0.5527\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2944 - accuracy: 0.5352 - val_loss: 1.3541 - val_accuracy: 0.5165\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2612 - accuracy: 0.5479 - val_loss: 1.4292 - val_accuracy: 0.5079\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2308 - accuracy: 0.5590 - val_loss: 1.5011 - val_accuracy: 0.4822\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1980 - accuracy: 0.5723 - val_loss: 1.1430 - val_accuracy: 0.5929\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1741 - accuracy: 0.5819 - val_loss: 1.1063 - val_accuracy: 0.6086\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1438 - accuracy: 0.5949 - val_loss: 1.0438 - val_accuracy: 0.6291\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1195 - accuracy: 0.6014 - val_loss: 1.1563 - val_accuracy: 0.6006\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0954 - accuracy: 0.6097 - val_loss: 1.1939 - val_accuracy: 0.5791\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0716 - accuracy: 0.6191 - val_loss: 1.0329 - val_accuracy: 0.6320\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0497 - accuracy: 0.6278 - val_loss: 0.9730 - val_accuracy: 0.6558\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0296 - accuracy: 0.6358 - val_loss: 0.9709 - val_accuracy: 0.6621\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0076 - accuracy: 0.6449 - val_loss: 1.2661 - val_accuracy: 0.5736\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9910 - accuracy: 0.6469 - val_loss: 1.0581 - val_accuracy: 0.6200\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9773 - accuracy: 0.6531 - val_loss: 1.1792 - val_accuracy: 0.5982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 1. Best model saved to best_model_step_size_1.h5.\n",
            "Loaded weights from best_model_step_size_1.h5\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 1.0115 - accuracy: 0.6426 - val_loss: 1.1563 - val_accuracy: 0.6000\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9944 - accuracy: 0.6496 - val_loss: 0.9304 - val_accuracy: 0.6735\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9748 - accuracy: 0.6567 - val_loss: 0.9375 - val_accuracy: 0.6666\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9581 - accuracy: 0.6613 - val_loss: 0.9447 - val_accuracy: 0.6646\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9426 - accuracy: 0.6669 - val_loss: 0.9601 - val_accuracy: 0.6621\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9316 - accuracy: 0.6694 - val_loss: 0.9519 - val_accuracy: 0.6605\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9142 - accuracy: 0.6768 - val_loss: 0.8614 - val_accuracy: 0.6916\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9008 - accuracy: 0.6841 - val_loss: 0.8838 - val_accuracy: 0.6860\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8820 - accuracy: 0.6869 - val_loss: 0.8347 - val_accuracy: 0.7049\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8699 - accuracy: 0.6923 - val_loss: 0.8703 - val_accuracy: 0.6916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 0.1. Best model saved to best_model_step_size_0.1.h5.\n",
            "Loaded weights from best_model_step_size_0.1.h5\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.8709 - accuracy: 0.6913 - val_loss: 1.0184 - val_accuracy: 0.6401\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8586 - accuracy: 0.6978 - val_loss: 0.8051 - val_accuracy: 0.7154\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8435 - accuracy: 0.7019 - val_loss: 0.8057 - val_accuracy: 0.7144\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8342 - accuracy: 0.7070 - val_loss: 0.8027 - val_accuracy: 0.7139\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8235 - accuracy: 0.7079 - val_loss: 0.7710 - val_accuracy: 0.7299\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8067 - accuracy: 0.7167 - val_loss: 0.8187 - val_accuracy: 0.7149\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7979 - accuracy: 0.7171 - val_loss: 0.8279 - val_accuracy: 0.7080\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7895 - accuracy: 0.7211 - val_loss: 0.8429 - val_accuracy: 0.7062\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7816 - accuracy: 0.7238 - val_loss: 0.7436 - val_accuracy: 0.7409\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7704 - accuracy: 0.7269 - val_loss: 0.7745 - val_accuracy: 0.7282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 0.01. Best model saved to best_model_step_size_0.01.h5.\n",
            "Loaded weights from best_model_step_size_0.01.h5\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.7709 - accuracy: 0.7288 - val_loss: 0.8312 - val_accuracy: 0.7106\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7577 - accuracy: 0.7318 - val_loss: 0.8539 - val_accuracy: 0.7019\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7488 - accuracy: 0.7374 - val_loss: 0.7523 - val_accuracy: 0.7360\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7399 - accuracy: 0.7393 - val_loss: 0.7697 - val_accuracy: 0.7309\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7316 - accuracy: 0.7395 - val_loss: 0.7230 - val_accuracy: 0.7476\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7199 - accuracy: 0.7476 - val_loss: 0.7230 - val_accuracy: 0.7420\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7155 - accuracy: 0.7500 - val_loss: 0.7778 - val_accuracy: 0.7279\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7035 - accuracy: 0.7509 - val_loss: 0.6901 - val_accuracy: 0.7570\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6995 - accuracy: 0.7536 - val_loss: 0.7268 - val_accuracy: 0.7402\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6902 - accuracy: 0.7560 - val_loss: 0.7145 - val_accuracy: 0.7505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 0.001. Best model saved to best_model_step_size_0.001.h5.\n",
            "Loaded weights from best_model_step_size_0.001.h5\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.6976 - accuracy: 0.7535 - val_loss: 0.9481 - val_accuracy: 0.6751\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6895 - accuracy: 0.7552 - val_loss: 0.6938 - val_accuracy: 0.7568\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6820 - accuracy: 0.7609 - val_loss: 0.7212 - val_accuracy: 0.7468\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6777 - accuracy: 0.7620 - val_loss: 0.6855 - val_accuracy: 0.7612\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6679 - accuracy: 0.7642 - val_loss: 0.7752 - val_accuracy: 0.7382\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6599 - accuracy: 0.7657 - val_loss: 0.6762 - val_accuracy: 0.7581\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6542 - accuracy: 0.7687 - val_loss: 0.6584 - val_accuracy: 0.7684\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6453 - accuracy: 0.7718 - val_loss: 0.6970 - val_accuracy: 0.7594\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6389 - accuracy: 0.7751 - val_loss: 0.6858 - val_accuracy: 0.7632\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6319 - accuracy: 0.7745 - val_loss: 0.6741 - val_accuracy: 0.7636\n",
            "Training completed with step size 0.0001. Best model saved to best_model_step_size_0.0001.h5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "\n",
        "# Define the sequence of step sizes\n",
        "step_sizes = [5,1, 0.1, 0.01, 0.001, 0.0001]\n",
        "epochs = [5,20,10,10,10,10]\n",
        "\n",
        "previous_best_model_path = None\n",
        "\n",
        "for i in range(len(step_sizes)):\n",
        "    # Initialize the model\n",
        "    step_size = step_sizes[i]\n",
        "    epoch = epochs[i]\n",
        "    model = create_cnn_model()\n",
        "\n",
        "    # If there's a model from the previous step, load its weights\n",
        "    if previous_best_model_path and os.path.exists(previous_best_model_path):\n",
        "        model.load_weights(previous_best_model_path)\n",
        "        print(f\"Loaded weights from {previous_best_model_path}\")\n",
        "\n",
        "    # Compile the model with the current step size\n",
        "    model.compile(optimizer=Adam(lr=step_size),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Define the checkpoint callback to save the best model\n",
        "    checkpoint_filepath = f'best_model_step_size_{step_size}.h5'\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train,\n",
        "              epochs=epoch,\n",
        "              batch_size=64,\n",
        "              validation_data=(x_test, y_test),\n",
        "              callbacks=[model_checkpoint_callback])\n",
        "\n",
        "    # Update the path of the best model for the next iteration\n",
        "    previous_best_model_path = checkpoint_filepath\n",
        "\n",
        "    print(f\"Training completed with step size {step_size}. Best model saved to {checkpoint_filepath}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0689ut9sAna",
        "outputId": "6a8b1da7-9d92-4472-fc55-53e4e05d3108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 9s 9ms/step - loss: 1.5687 - accuracy: 0.4271 - val_loss: 1.1948 - val_accuracy: 0.5671\n",
            "Epoch 2/5\n",
            " 15/782 [..............................] - ETA: 5s - loss: 1.2099 - accuracy: 0.5698"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1628 - accuracy: 0.5867 - val_loss: 1.0344 - val_accuracy: 0.6383\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9873 - accuracy: 0.6554 - val_loss: 0.8620 - val_accuracy: 0.7019\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8890 - accuracy: 0.6876 - val_loss: 0.8004 - val_accuracy: 0.7194\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8214 - accuracy: 0.7129 - val_loss: 0.8100 - val_accuracy: 0.7241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 5. Best model saved to best_model_step_size_5.h5.\n",
            "Loaded weights from best_model_step_size_5.h5\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 9s 9ms/step - loss: 0.7692 - accuracy: 0.7293 - val_loss: 0.7241 - val_accuracy: 0.7488\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7248 - accuracy: 0.7440 - val_loss: 0.7017 - val_accuracy: 0.7577\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6924 - accuracy: 0.7582 - val_loss: 0.6971 - val_accuracy: 0.7620\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6608 - accuracy: 0.7667 - val_loss: 0.6846 - val_accuracy: 0.7635\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6258 - accuracy: 0.7804 - val_loss: 0.7072 - val_accuracy: 0.7588\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6097 - accuracy: 0.7843 - val_loss: 0.6563 - val_accuracy: 0.7799\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5841 - accuracy: 0.7925 - val_loss: 0.6909 - val_accuracy: 0.7699\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5612 - accuracy: 0.8022 - val_loss: 0.6361 - val_accuracy: 0.7867\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5449 - accuracy: 0.8075 - val_loss: 0.6425 - val_accuracy: 0.7841\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5255 - accuracy: 0.8145 - val_loss: 0.6201 - val_accuracy: 0.7907\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5110 - accuracy: 0.8196 - val_loss: 0.6570 - val_accuracy: 0.7813\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5046 - accuracy: 0.8211 - val_loss: 0.6585 - val_accuracy: 0.7831\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4915 - accuracy: 0.8250 - val_loss: 0.6404 - val_accuracy: 0.7895\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4765 - accuracy: 0.8316 - val_loss: 0.6491 - val_accuracy: 0.7894\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4731 - accuracy: 0.8342 - val_loss: 0.6583 - val_accuracy: 0.7863\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4548 - accuracy: 0.8382 - val_loss: 0.6490 - val_accuracy: 0.7935\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4450 - accuracy: 0.8426 - val_loss: 0.6394 - val_accuracy: 0.7960\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4373 - accuracy: 0.8449 - val_loss: 0.6410 - val_accuracy: 0.7953\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4305 - accuracy: 0.8480 - val_loss: 0.6292 - val_accuracy: 0.7977\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4261 - accuracy: 0.8489 - val_loss: 0.6254 - val_accuracy: 0.7974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 1. Best model saved to best_model_step_size_1.h5.\n",
            "Loaded weights from best_model_step_size_1.h5\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 9s 9ms/step - loss: 0.4259 - accuracy: 0.8495 - val_loss: 0.6616 - val_accuracy: 0.7942\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4173 - accuracy: 0.8512 - val_loss: 0.6478 - val_accuracy: 0.7923\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4131 - accuracy: 0.8533 - val_loss: 0.6640 - val_accuracy: 0.7915\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4058 - accuracy: 0.8570 - val_loss: 0.6561 - val_accuracy: 0.7888\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4081 - accuracy: 0.8563 - val_loss: 0.6412 - val_accuracy: 0.7992\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3984 - accuracy: 0.8601 - val_loss: 0.6385 - val_accuracy: 0.8021\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3913 - accuracy: 0.8608 - val_loss: 0.6504 - val_accuracy: 0.8012\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3840 - accuracy: 0.8638 - val_loss: 0.6575 - val_accuracy: 0.7967\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3798 - accuracy: 0.8660 - val_loss: 0.6462 - val_accuracy: 0.7936\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3679 - accuracy: 0.8703 - val_loss: 0.6764 - val_accuracy: 0.7939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 0.1. Best model saved to best_model_step_size_0.1.h5.\n",
            "Loaded weights from best_model_step_size_0.1.h5\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.3991 - accuracy: 0.8599 - val_loss: 0.6277 - val_accuracy: 0.8033\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3882 - accuracy: 0.8639 - val_loss: 0.6297 - val_accuracy: 0.8047\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3903 - accuracy: 0.8622 - val_loss: 0.6627 - val_accuracy: 0.7977\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3791 - accuracy: 0.8676 - val_loss: 0.6665 - val_accuracy: 0.7984\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3807 - accuracy: 0.8659 - val_loss: 0.6478 - val_accuracy: 0.7960\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3725 - accuracy: 0.8683 - val_loss: 0.6608 - val_accuracy: 0.7999\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3616 - accuracy: 0.8714 - val_loss: 0.6537 - val_accuracy: 0.8010\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3630 - accuracy: 0.8716 - val_loss: 0.7020 - val_accuracy: 0.7868\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3602 - accuracy: 0.8718 - val_loss: 0.6581 - val_accuracy: 0.8018\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3546 - accuracy: 0.8762 - val_loss: 0.6597 - val_accuracy: 0.8015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 0.01. Best model saved to best_model_step_size_0.01.h5.\n",
            "Loaded weights from best_model_step_size_0.01.h5\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.3869 - accuracy: 0.8650 - val_loss: 0.6886 - val_accuracy: 0.7944\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3799 - accuracy: 0.8664 - val_loss: 0.6824 - val_accuracy: 0.7939\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3745 - accuracy: 0.8692 - val_loss: 0.6667 - val_accuracy: 0.7950\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3787 - accuracy: 0.8660 - val_loss: 0.6464 - val_accuracy: 0.8002\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3645 - accuracy: 0.8720 - val_loss: 0.6475 - val_accuracy: 0.8011\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3667 - accuracy: 0.8704 - val_loss: 0.6713 - val_accuracy: 0.7918\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3554 - accuracy: 0.8759 - val_loss: 0.6655 - val_accuracy: 0.7982\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3520 - accuracy: 0.8765 - val_loss: 0.6685 - val_accuracy: 0.7959\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3630 - accuracy: 0.8721 - val_loss: 0.6619 - val_accuracy: 0.7985\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3481 - accuracy: 0.8772 - val_loss: 0.6429 - val_accuracy: 0.8013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 0.001. Best model saved to best_model_step_size_0.001.h5.\n",
            "Loaded weights from best_model_step_size_0.001.h5\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 9s 9ms/step - loss: 0.3495 - accuracy: 0.8761 - val_loss: 0.6751 - val_accuracy: 0.8039\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3451 - accuracy: 0.8792 - val_loss: 0.6874 - val_accuracy: 0.7946\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3491 - accuracy: 0.8787 - val_loss: 0.6809 - val_accuracy: 0.7956\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3476 - accuracy: 0.8806 - val_loss: 0.6852 - val_accuracy: 0.7981\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3296 - accuracy: 0.8855 - val_loss: 0.7076 - val_accuracy: 0.7923\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3339 - accuracy: 0.8846 - val_loss: 0.7075 - val_accuracy: 0.7975\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3345 - accuracy: 0.8821 - val_loss: 0.6516 - val_accuracy: 0.8052\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3307 - accuracy: 0.8839 - val_loss: 0.6981 - val_accuracy: 0.7896\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3287 - accuracy: 0.8859 - val_loss: 0.6533 - val_accuracy: 0.8011\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3289 - accuracy: 0.8836 - val_loss: 0.6795 - val_accuracy: 0.7993\n",
            "Training completed with step size 0.0001. Best model saved to best_model_step_size_0.0001.h5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam, SGD, AdamW\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "\n",
        "# Define the sequence of step sizes\n",
        "step_sizes = [5,1, 0.1, 0.01, 0.001, 0.0001]\n",
        "epochs = [5,20,10,10,10,10]\n",
        "\n",
        "previous_best_model_path = None\n",
        "\n",
        "for i in range(len(step_sizes)):\n",
        "    # Initialize the model\n",
        "    step_size = step_sizes[i]\n",
        "    epoch = epochs[i]\n",
        "    model = create_cnn_model()\n",
        "\n",
        "    # If there's a model from the previous step, load its weights\n",
        "    if previous_best_model_path and os.path.exists(previous_best_model_path):\n",
        "        model.load_weights(previous_best_model_path)\n",
        "        print(f\"Loaded weights from {previous_best_model_path}\")\n",
        "\n",
        "    # Compile the model with the current step size\n",
        "    model.compile(optimizer=AdamW(lr=step_size),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Define the checkpoint callback to save the best model\n",
        "    checkpoint_filepath = f'best_model_step_size_{step_size}.h5'\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train,\n",
        "              epochs=epoch,\n",
        "              batch_size=64,\n",
        "              validation_data=(x_test, y_test),\n",
        "              callbacks=[model_checkpoint_callback])\n",
        "\n",
        "    # Update the path of the best model for the next iteration\n",
        "    previous_best_model_path = checkpoint_filepath\n",
        "\n",
        "    print(f\"Training completed with step size {step_size}. Best model saved to {checkpoint_filepath}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MwmJvJ3t25-",
        "outputId": "ed76e38f-338c-49d6-a32f-8b1e58f959a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.AdamW.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 9s 9ms/step - loss: 1.5455 - accuracy: 0.4315 - val_loss: 1.2471 - val_accuracy: 0.5493\n",
            "Epoch 2/5\n",
            " 15/782 [..............................] - ETA: 5s - loss: 1.1797 - accuracy: 0.5740"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1655 - accuracy: 0.5838 - val_loss: 0.9798 - val_accuracy: 0.6563\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9815 - accuracy: 0.6541 - val_loss: 0.9241 - val_accuracy: 0.6745\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8738 - accuracy: 0.6938 - val_loss: 0.8048 - val_accuracy: 0.7233\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.8114 - accuracy: 0.7147 - val_loss: 0.7432 - val_accuracy: 0.7466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.AdamW.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 5. Best model saved to best_model_step_size_5.h5.\n",
            "Loaded weights from best_model_step_size_5.h5\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 9s 9ms/step - loss: 0.7546 - accuracy: 0.7358 - val_loss: 0.7526 - val_accuracy: 0.7352\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7136 - accuracy: 0.7501 - val_loss: 0.7120 - val_accuracy: 0.7515\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6803 - accuracy: 0.7612 - val_loss: 0.6791 - val_accuracy: 0.7684\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6474 - accuracy: 0.7728 - val_loss: 0.6639 - val_accuracy: 0.7670\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6198 - accuracy: 0.7832 - val_loss: 0.6608 - val_accuracy: 0.7735\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5976 - accuracy: 0.7906 - val_loss: 0.6274 - val_accuracy: 0.7839\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5770 - accuracy: 0.7982 - val_loss: 0.6274 - val_accuracy: 0.7851\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5560 - accuracy: 0.8050 - val_loss: 0.6430 - val_accuracy: 0.7839\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5417 - accuracy: 0.8093 - val_loss: 0.6112 - val_accuracy: 0.7935\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5225 - accuracy: 0.8147 - val_loss: 0.6369 - val_accuracy: 0.7864\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5089 - accuracy: 0.8201 - val_loss: 0.6354 - val_accuracy: 0.7871\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4993 - accuracy: 0.8233 - val_loss: 0.6846 - val_accuracy: 0.7720\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4862 - accuracy: 0.8272 - val_loss: 0.6262 - val_accuracy: 0.7931\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4692 - accuracy: 0.8341 - val_loss: 0.6477 - val_accuracy: 0.7888\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4642 - accuracy: 0.8368 - val_loss: 0.6149 - val_accuracy: 0.7983\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4521 - accuracy: 0.8399 - val_loss: 0.6271 - val_accuracy: 0.7891\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4464 - accuracy: 0.8423 - val_loss: 0.6061 - val_accuracy: 0.8031\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4327 - accuracy: 0.8464 - val_loss: 0.5965 - val_accuracy: 0.8050\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4186 - accuracy: 0.8516 - val_loss: 0.6138 - val_accuracy: 0.8012\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4186 - accuracy: 0.8507 - val_loss: 0.5969 - val_accuracy: 0.8024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.AdamW.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 1. Best model saved to best_model_step_size_1.h5.\n",
            "Loaded weights from best_model_step_size_1.h5\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 9s 9ms/step - loss: 0.4264 - accuracy: 0.8487 - val_loss: 0.6078 - val_accuracy: 0.8070\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4163 - accuracy: 0.8534 - val_loss: 0.6339 - val_accuracy: 0.7967\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4164 - accuracy: 0.8527 - val_loss: 0.6542 - val_accuracy: 0.7962\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4064 - accuracy: 0.8549 - val_loss: 0.6263 - val_accuracy: 0.7949\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3973 - accuracy: 0.8592 - val_loss: 0.6401 - val_accuracy: 0.8003\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3872 - accuracy: 0.8621 - val_loss: 0.6378 - val_accuracy: 0.7952\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3915 - accuracy: 0.8634 - val_loss: 0.6312 - val_accuracy: 0.7956\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3880 - accuracy: 0.8631 - val_loss: 0.6030 - val_accuracy: 0.8056\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3806 - accuracy: 0.8647 - val_loss: 0.6257 - val_accuracy: 0.7994\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3728 - accuracy: 0.8682 - val_loss: 0.6095 - val_accuracy: 0.8088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.AdamW.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 0.1. Best model saved to best_model_step_size_0.1.h5.\n",
            "Loaded weights from best_model_step_size_0.1.h5\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 9s 9ms/step - loss: 0.3704 - accuracy: 0.8697 - val_loss: 0.6347 - val_accuracy: 0.8008\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3720 - accuracy: 0.8679 - val_loss: 0.6244 - val_accuracy: 0.8028\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3634 - accuracy: 0.8722 - val_loss: 0.6242 - val_accuracy: 0.8049\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3609 - accuracy: 0.8728 - val_loss: 0.6441 - val_accuracy: 0.8031\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3611 - accuracy: 0.8741 - val_loss: 0.6238 - val_accuracy: 0.8030\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3493 - accuracy: 0.8768 - val_loss: 0.6083 - val_accuracy: 0.8080\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3445 - accuracy: 0.8789 - val_loss: 0.6121 - val_accuracy: 0.8053\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3465 - accuracy: 0.8772 - val_loss: 0.6438 - val_accuracy: 0.8002\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3397 - accuracy: 0.8802 - val_loss: 0.6300 - val_accuracy: 0.8072\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3425 - accuracy: 0.8797 - val_loss: 0.6322 - val_accuracy: 0.8060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.AdamW.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 0.01. Best model saved to best_model_step_size_0.01.h5.\n",
            "Loaded weights from best_model_step_size_0.01.h5\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 9s 9ms/step - loss: 0.3566 - accuracy: 0.8770 - val_loss: 0.6255 - val_accuracy: 0.8091\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3423 - accuracy: 0.8798 - val_loss: 0.6303 - val_accuracy: 0.7997\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3430 - accuracy: 0.8781 - val_loss: 0.6471 - val_accuracy: 0.8019\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3377 - accuracy: 0.8804 - val_loss: 0.6689 - val_accuracy: 0.7968\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3330 - accuracy: 0.8810 - val_loss: 0.6344 - val_accuracy: 0.8090\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3395 - accuracy: 0.8801 - val_loss: 0.6378 - val_accuracy: 0.8043\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3287 - accuracy: 0.8854 - val_loss: 0.6472 - val_accuracy: 0.8032\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3259 - accuracy: 0.8840 - val_loss: 0.6373 - val_accuracy: 0.8043\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3263 - accuracy: 0.8861 - val_loss: 0.6374 - val_accuracy: 0.8028\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3195 - accuracy: 0.8872 - val_loss: 0.6417 - val_accuracy: 0.8041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.AdamW.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed with step size 0.001. Best model saved to best_model_step_size_0.001.h5.\n",
            "Loaded weights from best_model_step_size_0.001.h5\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 9s 9ms/step - loss: 0.3564 - accuracy: 0.8763 - val_loss: 0.6528 - val_accuracy: 0.7973\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3432 - accuracy: 0.8783 - val_loss: 0.6250 - val_accuracy: 0.8067\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3409 - accuracy: 0.8802 - val_loss: 0.6383 - val_accuracy: 0.8061\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3385 - accuracy: 0.8807 - val_loss: 0.6342 - val_accuracy: 0.8088\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3373 - accuracy: 0.8821 - val_loss: 0.6303 - val_accuracy: 0.7993\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3250 - accuracy: 0.8849 - val_loss: 0.6336 - val_accuracy: 0.8100\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3243 - accuracy: 0.8864 - val_loss: 0.6321 - val_accuracy: 0.8031\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3370 - accuracy: 0.8822 - val_loss: 0.6557 - val_accuracy: 0.8034\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3328 - accuracy: 0.8838 - val_loss: 0.6186 - val_accuracy: 0.8087\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3241 - accuracy: 0.8858 - val_loss: 0.6357 - val_accuracy: 0.8027\n",
            "Training completed with step size 0.0001. Best model saved to best_model_step_size_0.0001.h5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "step_sizes = [10,5, 1, 0.1, 0.01, 0.001, 0.0001]\n",
        "epochs = [5,10, 20, 10, 10, 10, 10]\n",
        "\n",
        "previous_best_model_path = None\n",
        "best_validation_accuracy = 0  # Track the best validation accuracy\n",
        "\n",
        "for i in range(len(step_sizes)):\n",
        "    step_size = step_sizes[i]\n",
        "    epoch = epochs[i]\n",
        "    model = create_cnn_model()  # Initialize the model\n",
        "\n",
        "    # Load weights from the previous best model if it exists\n",
        "    if previous_best_model_path and os.path.exists(previous_best_model_path):\n",
        "        model.load_weights(previous_best_model_path)\n",
        "        print(f\"Loaded weights from {previous_best_model_path}\")\n",
        "\n",
        "    # Compile the model with the current step size\n",
        "    model.compile(optimizer=AdamW(lr=step_size),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Define the checkpoint callback to save the best model for the current step size\n",
        "    checkpoint_filepath = f'best_model_step_size_{step_size}.h5'\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train,\n",
        "              epochs=epoch,\n",
        "              batch_size=64,\n",
        "              validation_data=(x_test, y_test),\n",
        "              callbacks=[model_checkpoint_callback])\n",
        "\n",
        "    # Load the best model saved during the current training session to compare its performance\n",
        "    current_best_model = load_model(checkpoint_filepath)\n",
        "    val_loss, val_accuracy = current_best_model.evaluate(x_test, y_test)\n",
        "\n",
        "    # Update the path of the best model if the current one is better\n",
        "    if val_accuracy > best_validation_accuracy:\n",
        "        best_validation_accuracy = val_accuracy\n",
        "        previous_best_model_path = checkpoint_filepath\n",
        "        print(f\"New best model with validation accuracy {val_accuracy}, saved to {checkpoint_filepath}.\")\n",
        "    else:\n",
        "        os.remove(checkpoint_filepath)  # Optionally remove the current checkpoint if it's not the best\n",
        "        print(f\"Training completed with step size {step_size}. Best model remains {previous_best_model_path} with validation accuracy {best_validation_accuracy}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "mtDQKa9ouyZr",
        "outputId": "848044f2-fd15-4a43-c0f0-14105c08c3a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.AdamW.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "376/782 [=============>................] - ETA: 3s - loss: 1.7311 - accuracy: 0.3577"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-315ba1eb6a70>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     model.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m     32\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1796\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1799\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[1;32m   1800\u001b[0m                             \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m             \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1412\u001b[0m             can_run_full_execution = (\n\u001b[1;32m   1413\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    691\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    837\u001b[0m     \"\"\"\n\u001b[1;32m    838\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m     \u001b[0;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[0;34m(self, no_copy)\u001b[0m\n\u001b[1;32m    816\u001b[0m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[0;34m(no_copy)\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mno_copy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mforward_compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_compatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2022\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0mgen_resource_variable_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_copy_on_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[0m\u001b[1;32m    809\u001b[0m           self.handle, self._dtype)\n\u001b[1;32m    810\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    532\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    535\u001b[0m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[1;32m    536\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "\n",
        "# Define the sequence of step sizes and epochs\n",
        "step_sizes = [50,10,5, 1, 0.1, 0.01, 0.001, 0.0003,0.0001]\n",
        "epochs = [5,5,10, 20, 10, 10, 10, 20, 20]\n",
        "\n",
        "overall_best_model_path = 'overall_best_model.h5'  # Path for the overall best model\n",
        "best_validation_accuracy = 0  # Track the best validation accuracy\n",
        "\n",
        "for i in range(len(step_sizes)):\n",
        "    step_size = step_sizes[i]\n",
        "    epoch = epochs[i]\n",
        "    model = create_cnn_model()  # Initialize the model\n",
        "\n",
        "    # Load weights from the overall best model if it exists\n",
        "    if os.path.exists(overall_best_model_path):\n",
        "        model.load_weights(overall_best_model_path)\n",
        "        print(f\"Loaded weights from the overall best model\")\n",
        "\n",
        "    # Compile the model with the current step size\n",
        "    model.compile(optimizer=Adam(lr=step_size),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Use a temporary checkpoint path for the current training session\n",
        "    temp_checkpoint_filepath = 'temp_best_model.h5'\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        filepath=temp_checkpoint_filepath,\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train,\n",
        "              epochs=epoch,\n",
        "              batch_size=64,\n",
        "              validation_data=(x_test, y_test),\n",
        "              callbacks=[model_checkpoint_callback])\n",
        "\n",
        "    # Load the temporarily saved model to compare its performance\n",
        "    temp_best_model = load_model(temp_checkpoint_filepath)\n",
        "    val_loss, val_accuracy = temp_best_model.evaluate(x_test, y_test)\n",
        "\n",
        "    # If the temporary model is better, update the overall best model\n",
        "    if val_accuracy > best_validation_accuracy:\n",
        "        best_validation_accuracy = val_accuracy\n",
        "        # Replace the overall best model with the new best\n",
        "        os.rename(temp_checkpoint_filepath, overall_best_model_path)\n",
        "        print(f\"Updated the overall best model with validation accuracy {val_accuracy}.\")\n",
        "    else:\n",
        "        # Delete the temporary model if it's not the best\n",
        "        os.remove(temp_checkpoint_filepath)\n",
        "        print(f\"Step size {step_size} training completed. No update to the overall best model.\")\n",
        "\n",
        "# At the end, the overall_best_model_path points to the model with the highest validation accuracy across all step sizes."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8f3sfQdwm32",
        "outputId": "fac70af0-2139-4148-e439-ecce43ce6be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 1.5915 - accuracy: 0.4118 - val_loss: 1.2195 - val_accuracy: 0.5654\n",
            "Epoch 2/5\n",
            " 15/782 [..............................] - ETA: 5s - loss: 1.2283 - accuracy: 0.5542"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1613 - accuracy: 0.5874 - val_loss: 0.9990 - val_accuracy: 0.6454\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9903 - accuracy: 0.6510 - val_loss: 0.8752 - val_accuracy: 0.6889\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8824 - accuracy: 0.6901 - val_loss: 0.8282 - val_accuracy: 0.7087\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8095 - accuracy: 0.7161 - val_loss: 0.7828 - val_accuracy: 0.7294\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.7828 - accuracy: 0.7294\n",
            "Updated the overall best model with validation accuracy 0.7293999791145325.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded weights from the overall best model\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.7508 - accuracy: 0.7378 - val_loss: 0.7150 - val_accuracy: 0.7485\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7154 - accuracy: 0.7470 - val_loss: 0.6900 - val_accuracy: 0.7609\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6796 - accuracy: 0.7620 - val_loss: 0.6818 - val_accuracy: 0.7677\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6446 - accuracy: 0.7719 - val_loss: 0.6773 - val_accuracy: 0.7714\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6114 - accuracy: 0.7842 - val_loss: 0.6949 - val_accuracy: 0.7635\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5910 - accuracy: 0.7919 - val_loss: 0.6569 - val_accuracy: 0.7771\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5638 - accuracy: 0.8013 - val_loss: 0.6331 - val_accuracy: 0.7846\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5481 - accuracy: 0.8062 - val_loss: 0.6669 - val_accuracy: 0.7747\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5311 - accuracy: 0.8123 - val_loss: 0.6479 - val_accuracy: 0.7835\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5206 - accuracy: 0.8168 - val_loss: 0.6400 - val_accuracy: 0.7834\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.6330 - accuracy: 0.7846\n",
            "Updated the overall best model with validation accuracy 0.784600019454956.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded weights from the overall best model\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.5513 - accuracy: 0.8045 - val_loss: 0.6438 - val_accuracy: 0.7857\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5302 - accuracy: 0.8126 - val_loss: 0.6432 - val_accuracy: 0.7786\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5120 - accuracy: 0.8193 - val_loss: 0.6282 - val_accuracy: 0.7877\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4951 - accuracy: 0.8239 - val_loss: 0.6248 - val_accuracy: 0.7890\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4871 - accuracy: 0.8263 - val_loss: 0.6206 - val_accuracy: 0.7942\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4702 - accuracy: 0.8330 - val_loss: 0.6365 - val_accuracy: 0.7883\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4670 - accuracy: 0.8349 - val_loss: 0.6378 - val_accuracy: 0.7952\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4534 - accuracy: 0.8394 - val_loss: 0.6725 - val_accuracy: 0.7820\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4484 - accuracy: 0.8418 - val_loss: 0.6227 - val_accuracy: 0.7944\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4322 - accuracy: 0.8460 - val_loss: 0.6632 - val_accuracy: 0.7900\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4245 - accuracy: 0.8497 - val_loss: 0.6405 - val_accuracy: 0.7906\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4209 - accuracy: 0.8515 - val_loss: 0.6203 - val_accuracy: 0.8015\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4068 - accuracy: 0.8558 - val_loss: 0.6199 - val_accuracy: 0.7990\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4020 - accuracy: 0.8587 - val_loss: 0.6483 - val_accuracy: 0.7944\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4012 - accuracy: 0.8574 - val_loss: 0.6466 - val_accuracy: 0.7933\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3893 - accuracy: 0.8603 - val_loss: 0.6480 - val_accuracy: 0.7974\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3865 - accuracy: 0.8625 - val_loss: 0.6300 - val_accuracy: 0.7997\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3777 - accuracy: 0.8660 - val_loss: 0.6313 - val_accuracy: 0.8018\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3780 - accuracy: 0.8642 - val_loss: 0.6354 - val_accuracy: 0.8002\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3746 - accuracy: 0.8675 - val_loss: 0.6313 - val_accuracy: 0.8024\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.6313 - accuracy: 0.8024\n",
            "Updated the overall best model with validation accuracy 0.8023999929428101.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded weights from the overall best model\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.3726 - accuracy: 0.8674 - val_loss: 0.6522 - val_accuracy: 0.7960\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3560 - accuracy: 0.8739 - val_loss: 0.6502 - val_accuracy: 0.7983\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3665 - accuracy: 0.8699 - val_loss: 0.6505 - val_accuracy: 0.8041\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3557 - accuracy: 0.8728 - val_loss: 0.6462 - val_accuracy: 0.7990\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3544 - accuracy: 0.8734 - val_loss: 0.6563 - val_accuracy: 0.8005\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3495 - accuracy: 0.8769 - val_loss: 0.6521 - val_accuracy: 0.7983\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3438 - accuracy: 0.8785 - val_loss: 0.6492 - val_accuracy: 0.7998\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3471 - accuracy: 0.8774 - val_loss: 0.6637 - val_accuracy: 0.7949\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3387 - accuracy: 0.8799 - val_loss: 0.6572 - val_accuracy: 0.8019\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3339 - accuracy: 0.8811 - val_loss: 0.6555 - val_accuracy: 0.8023\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.6505 - accuracy: 0.8041\n",
            "Updated the overall best model with validation accuracy 0.804099977016449.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded weights from the overall best model\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.3607 - accuracy: 0.8732 - val_loss: 0.6419 - val_accuracy: 0.8028\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3530 - accuracy: 0.8744 - val_loss: 0.6509 - val_accuracy: 0.8017\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3507 - accuracy: 0.8765 - val_loss: 0.6702 - val_accuracy: 0.7998\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3403 - accuracy: 0.8798 - val_loss: 0.6467 - val_accuracy: 0.7987\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3457 - accuracy: 0.8786 - val_loss: 0.6705 - val_accuracy: 0.7949\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3524 - accuracy: 0.8769 - val_loss: 0.6288 - val_accuracy: 0.8032\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3394 - accuracy: 0.8813 - val_loss: 0.6766 - val_accuracy: 0.8012\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3381 - accuracy: 0.8815 - val_loss: 0.6534 - val_accuracy: 0.7985\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3269 - accuracy: 0.8845 - val_loss: 0.6682 - val_accuracy: 0.7996\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3304 - accuracy: 0.8835 - val_loss: 0.6618 - val_accuracy: 0.8037\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.6618 - accuracy: 0.8037\n",
            "Step size 0.01 training completed. No update to the overall best model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded weights from the overall best model\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.3618 - accuracy: 0.8714 - val_loss: 0.6272 - val_accuracy: 0.8070\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3559 - accuracy: 0.8729 - val_loss: 0.6547 - val_accuracy: 0.7948\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3515 - accuracy: 0.8763 - val_loss: 0.6631 - val_accuracy: 0.8013\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3472 - accuracy: 0.8779 - val_loss: 0.6411 - val_accuracy: 0.8035\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3454 - accuracy: 0.8787 - val_loss: 0.6579 - val_accuracy: 0.8004\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3466 - accuracy: 0.8780 - val_loss: 0.6892 - val_accuracy: 0.7910\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3369 - accuracy: 0.8786 - val_loss: 0.6569 - val_accuracy: 0.8016\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3348 - accuracy: 0.8819 - val_loss: 0.6810 - val_accuracy: 0.7988\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3337 - accuracy: 0.8831 - val_loss: 0.6748 - val_accuracy: 0.8016\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3298 - accuracy: 0.8829 - val_loss: 0.6444 - val_accuracy: 0.7993\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.6272 - accuracy: 0.8070\n",
            "Updated the overall best model with validation accuracy 0.8069999814033508.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded weights from the overall best model\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.3619 - accuracy: 0.8734 - val_loss: 0.6578 - val_accuracy: 0.7932\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3528 - accuracy: 0.8748 - val_loss: 0.6530 - val_accuracy: 0.7993\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3510 - accuracy: 0.8771 - val_loss: 0.6595 - val_accuracy: 0.7993\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3457 - accuracy: 0.8777 - val_loss: 0.6603 - val_accuracy: 0.7976\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3441 - accuracy: 0.8797 - val_loss: 0.6603 - val_accuracy: 0.7980\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3348 - accuracy: 0.8818 - val_loss: 0.6743 - val_accuracy: 0.7985\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3410 - accuracy: 0.8808 - val_loss: 0.6676 - val_accuracy: 0.8022\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3305 - accuracy: 0.8857 - val_loss: 0.7032 - val_accuracy: 0.7933\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3372 - accuracy: 0.8821 - val_loss: 0.6990 - val_accuracy: 0.7928\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3261 - accuracy: 0.8851 - val_loss: 0.6713 - val_accuracy: 0.8020\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3201 - accuracy: 0.8866 - val_loss: 0.6843 - val_accuracy: 0.8007\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3250 - accuracy: 0.8862 - val_loss: 0.6588 - val_accuracy: 0.8026\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3287 - accuracy: 0.8850 - val_loss: 0.6760 - val_accuracy: 0.7987\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3125 - accuracy: 0.8906 - val_loss: 0.6777 - val_accuracy: 0.7981\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3225 - accuracy: 0.8860 - val_loss: 0.6625 - val_accuracy: 0.8003\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3154 - accuracy: 0.8905 - val_loss: 0.6947 - val_accuracy: 0.7916\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3186 - accuracy: 0.8873 - val_loss: 0.6562 - val_accuracy: 0.7976\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3086 - accuracy: 0.8908 - val_loss: 0.6712 - val_accuracy: 0.8018\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3051 - accuracy: 0.8935 - val_loss: 0.6889 - val_accuracy: 0.7961\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3067 - accuracy: 0.8918 - val_loss: 0.6805 - val_accuracy: 0.7967\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.6588 - accuracy: 0.8026\n",
            "Step size 0.0003 training completed. No update to the overall best model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded weights from the overall best model\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.3623 - accuracy: 0.8751 - val_loss: 0.6589 - val_accuracy: 0.7987\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3559 - accuracy: 0.8740 - val_loss: 0.6688 - val_accuracy: 0.8035\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3400 - accuracy: 0.8804 - val_loss: 0.6709 - val_accuracy: 0.7961\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3454 - accuracy: 0.8800 - val_loss: 0.6739 - val_accuracy: 0.7942\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3419 - accuracy: 0.8799 - val_loss: 0.6296 - val_accuracy: 0.8019\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3422 - accuracy: 0.8800 - val_loss: 0.6843 - val_accuracy: 0.7951\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3399 - accuracy: 0.8815 - val_loss: 0.6460 - val_accuracy: 0.7971\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3258 - accuracy: 0.8854 - val_loss: 0.6681 - val_accuracy: 0.8044\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3244 - accuracy: 0.8849 - val_loss: 0.6515 - val_accuracy: 0.8038\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3335 - accuracy: 0.8830 - val_loss: 0.6429 - val_accuracy: 0.7983\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3261 - accuracy: 0.8836 - val_loss: 0.6757 - val_accuracy: 0.7985\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3314 - accuracy: 0.8846 - val_loss: 0.6791 - val_accuracy: 0.7962\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3222 - accuracy: 0.8865 - val_loss: 0.7130 - val_accuracy: 0.7911\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3165 - accuracy: 0.8877 - val_loss: 0.6412 - val_accuracy: 0.8039\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3204 - accuracy: 0.8882 - val_loss: 0.6723 - val_accuracy: 0.8027\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3201 - accuracy: 0.8870 - val_loss: 0.6414 - val_accuracy: 0.8035\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3150 - accuracy: 0.8901 - val_loss: 0.6680 - val_accuracy: 0.8008\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3113 - accuracy: 0.8912 - val_loss: 0.6520 - val_accuracy: 0.8050\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3107 - accuracy: 0.8917 - val_loss: 0.6857 - val_accuracy: 0.7992\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3103 - accuracy: 0.8917 - val_loss: 0.6839 - val_accuracy: 0.7901\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.6520 - accuracy: 0.8050\n",
            "Step size 0.0001 training completed. No update to the overall best model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "\n",
        "# Define the sequence of step sizes and epochs\n",
        "step_sizes = [50,10,5, 1, 0.1, 0.01, 0.001, 0.0003,0.0001]\n",
        "epochs = [5,5,10, 20, 10, 10, 10, 20, 20]\n",
        "sequence = [[5,4,3,2,1], [1,1,0.1,0.1,0.01], [1,0.1,0.01,0.01,0.01], [.1,.01,.001,.001,.001], [.001,.001,.0003,.0001,.0001]]\n",
        "\n",
        "overall_best_model_path = 'overall_best_model.h5'  # Path for the overall best model\n",
        "best_validation_accuracy = 0  # Track the best validation accuracy\n",
        "\n",
        "for i in range(len(step_sizes)):\n",
        "    step_size = step_sizes[i]\n",
        "    epoch = epochs[i]\n",
        "    model = create_cnn_model()  # Initialize the model\n",
        "\n",
        "    # Load weights from the overall best model if it exists\n",
        "    if os.path.exists(overall_best_model_path):\n",
        "        model.load_weights(overall_best_model_path)\n",
        "        print(f\"Loaded weights from the overall best model\")\n",
        "\n",
        "    # Compile the model with the current step size\n",
        "    model.compile(optimizer=Adam(lr=step_size),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Use a temporary checkpoint path for the current training session\n",
        "    temp_checkpoint_filepath = 'temp_best_model.h5'\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        filepath=temp_checkpoint_filepath,\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train,\n",
        "              epochs=epoch,\n",
        "              batch_size=64,\n",
        "              validation_data=(x_test, y_test),\n",
        "              callbacks=[model_checkpoint_callback])\n",
        "\n",
        "    # Load the temporarily saved model to compare its performance\n",
        "    temp_best_model = load_model(temp_checkpoint_filepath)\n",
        "    val_loss, val_accuracy = temp_best_model.evaluate(x_test, y_test)\n",
        "\n",
        "    # If the temporary model is better, update the overall best model\n",
        "    if val_accuracy > best_validation_accuracy:\n",
        "        best_validation_accuracy = val_accuracy\n",
        "        # Replace the overall best model with the new best\n",
        "        os.rename(temp_checkpoint_filepath, overall_best_model_path)\n",
        "        print(f\"Updated the overall best model with validation accuracy {val_accuracy}.\")\n",
        "    else:\n",
        "        # Delete the temporary model if it's not the best\n",
        "        os.remove(temp_checkpoint_filepath)\n",
        "        print(f\"Step size {step_size} training completed. No update to the overall best model.\")"
      ],
      "metadata": {
        "id": "NNKtfDl95zmI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}